# Model Card: best

*Generated by ONNX Autodoc v0.1.0 on 2025-12-03T09:12:51.985354Z*

## Metadata

| Property | Value |
|----------|-------|
| IR Version | 8 |
| Producer | pytorch 2.5.1 |
| Opsets | ai.onnx:17 |

## Graph Summary

- **Nodes**: 392
- **Inputs**: 1
- **Outputs**: 1
- **Initializers**: 207

### Inputs

- `images`: [1, 3, 640, 640]

### Outputs

- `output0`: [1, 5, 8400]

### Operator Distribution

| Operator | Count |
|----------|-------|
| Conv | 104 |
| Mul | 100 |
| Sigmoid | 98 |
| Constant | 21 |
| Add | 21 |
| Concat | 19 |
| Split | 9 |
| Reshape | 5 |
| MaxPool | 3 |
| Resize | 2 |
| Div | 2 |
| Slice | 2 |
| Sub | 2 |
| Transpose | 1 |
| Softmax | 1 |
| ... | (2 more) |


## Visualizations

### Complexity Overview

![Complexity Summary](assets\complexity_summary.png)

### Operator Distribution

![Operator Histogram](assets\op_histogram.png)

### Parameter Distribution

![Parameter Distribution](assets\param_distribution.png)

### FLOPs Distribution

![FLOPs Distribution](assets\flops_distribution.png)


## Complexity Metrics

- **Total Parameters**: 43.61M
  - Trainable: 43.61M
  - Non-trainable: 0
  - By Precision: fp32: 43.61M

- **Estimated FLOPs**: 165.09B

- **Model Size**: 174.43 MB
- **Peak Activation Memory** (batch=1): 85.20 MB

### KV Cache (Transformer Inference)

- **Per Token**: 6.14 KB
- **Full Context** (seq=640): 3.93 MB
- **Layers**: 1
- **Hidden Dim**: 768

### Memory Breakdown by Op Type

| Component | Size |
|-----------|------|
| Conv | 174.43 MB |

## Architecture

**Detected Type**: cnn

### Detected Blocks

- ConvSigmoid: 97
- ResidualGate: 97
- ResidualAdd: 21
- ResidualConcat: 5
- RepeatedBlock: 4
- ResidualSub: 2

### Non-Standard Skip Connections

This model uses 104 non-standard skip connection(s):

- **Concat-based (DenseNet-style)**: 5
- **Gated skip (Highway/attention)**: 97
- **Subtraction-based**: 2

## Hardware Estimates

**Target Device**: NVIDIA GeForce RTX 4050 Laptop GPU (detected)
**Precision**: fp16 | **Batch Size**: 1

| Metric | Value |
|--------|-------|
| VRAM Required | 206.89 MB |
| Fits in VRAM | Yes |
| Theoretical Latency | 8.25 ms |
| Bottleneck | compute |
| Compute Utilization | 70% |
| GPU Saturation | 8.25e-03 (0.8255%) |

### Device Specifications

- **VRAM**: 6.44 GB
- **FP32 Peak**: 10.0 TFLOPS
- **FP16 Peak**: 20.0 TFLOPS

## System Requirements

| Level | Device | VRAM |
|-------|--------|------|
| Minimum | NVIDIA Jetson Nano 2GB | 0.19 GB |
| Recommended | NVIDIA Jetson Orin NX 16GB | 0.19 GB |
| Optimal | NVIDIA DGX H100 | - |

## Batch Size Scaling

**Optimal Batch Size**: 1

| Batch Size | Latency (ms) | Throughput (inf/s) | VRAM (GB) |
|------------|--------------|--------------------|-----------|
| 1 | 8.25 | 121.1 | 0.19 |
| 2 | 16.51 | 121.1 | 0.29 |
| 4 | 33.02 | 121.1 | 0.48 |
| 8 | 66.04 | 121.1 | 0.86 |
| 16 | 132.07 | 121.1 | 1.62 |
| 32 | 330.20 | 96.9 | 3.14 |
| 64 | inf | 0.0 | 6.19 |
| 128 | inf | 0.0 | 12.28 |

## Risk Signals

### [INFO] missing_normalization

Model has 104 trainable layers but no normalization layers detected. This may affect training stability.

**Recommendation**: If this model will be fine-tuned, consider adding normalization layers. For inference-only, this is typically not a concern.

### [INFO] nonstandard_residuals

Model uses 104 non-standard skip connection(s): 5 concat-based (DenseNet-style), 97 gated (Highway/attention gate), 2 subtraction-based. Model also has 21 standard Add-based residuals. These patterns may indicate custom architectures requiring special attention.

**Recommendation**: Non-standard skip connections are valid but may need special handling: Concat-based patterns increase tensor sizes through the network. Gated patterns add compute overhead but enable selective information flow. Ensure your deployment target and optimization tools support these patterns.
