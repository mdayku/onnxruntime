# Model Card: mnist

*Generated by ONNX Autodoc v0.1.0 on 2025-12-02T17:59:41.201583Z*

## Metadata

| Property | Value |
|----------|-------|
| IR Version | 3 |
| Producer | CNTK 2.5.1 |
| Opsets | ai.onnx:8 |


## Executive Summary

**TL;DR:** The model "mnist.onnx" is a multi-layer perceptron (MLP) designed for digit classification tasks, with a size of approximately 23.9 KB and a total of 5,998 parameters. Its primary use case is recognizing handwritten digits from the MNIST dataset.


The analyzed ONNX model, "mnist.onnx," is structured as a multi-layer perceptron (MLP) designed for digit classification tasks, featuring a total of 12 nodes with a single input of shape 1x1x28x28 and an output of shape 1x10. The model contains approximately 5,998 parameters and requires about 1.6 million floating-point operations (FLOPs), with a memory footprint of 23,992 bytes and peak activation memory of 75,264 bytes. Key architectural patterns include convolutional layers, activation functions (ReLU), and pooling operations, which are typical for image processing tasks. Deployment on an NVIDIA GeForce RTX 4050 Laptop GPU is feasible, as the model fits within the available VRAM and has a low theoretical latency of approximately 0.0003 ms; however, memory bandwidth may become a bottleneck during execution. It is recommended to monitor memory usage closely during deployment to ensure optimal performance and to consider potential optimizations if scaling to larger datasets or batch sizes.


*Generated by gpt-4o-mini*


## Graph Summary

- **Nodes**: 12
- **Inputs**: 1
- **Outputs**: 1
- **Initializers**: 8

### Inputs

- `Input3`: [1, 1, 28, 28]

### Outputs

- `Plus214_Output_0`: [1, 10]

### Operator Distribution

| Operator | Count |
|----------|-------|
| Add | 3 |
| Reshape | 2 |
| Conv | 2 |
| Relu | 2 |
| MaxPool | 2 |
| MatMul | 1 |


## Visualizations

### Complexity Overview

![Complexity Summary](demo_assets\complexity_summary.png)

### Operator Distribution

![Operator Histogram](demo_assets\op_histogram.png)

### Parameter Distribution

![Parameter Distribution](demo_assets\param_distribution.png)

### FLOPs Distribution

![FLOPs Distribution](demo_assets\flops_distribution.png)


## Complexity Metrics

- **Total Parameters**: 6.00K
  - Trainable: 6.00K
  - Non-trainable: 0

- **Estimated FLOPs**: 1.60M

- **Model Size**: 23.99 KB
- **Peak Activation Memory** (batch=1): 75.26 KB

## Architecture

**Detected Type**: mlp

## Hardware Estimates

**Target Device**: NVIDIA GeForce RTX 4050 Laptop GPU (detected)
**Precision**: fp32 | **Batch Size**: 1

| Metric | Value |
|--------|-------|
| VRAM Required | 119.11 KB |
| Fits in VRAM | Yes |
| Theoretical Latency | 0.00 ms |
| Bottleneck | memory_bandwidth |
| Compute Utilization | 49% |

### Device Specifications

- **VRAM**: 6.44 GB
- **FP32 Peak**: 10.0 TFLOPS
- **FP16 Peak**: 20.0 TFLOPS
