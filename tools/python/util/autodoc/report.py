# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

"""
Report generation and ModelInspector orchestrator for ONNX Autodoc.

This module contains:
- InspectionReport: The main data structure holding all analysis results
- ModelInspector: Orchestrator that coordinates all analysis components
"""
from __future__ import annotations

import json
import logging
import pathlib
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from .analyzer import (
        FlopCounts,
        MemoryEstimates,
        MetricsEngine,
        ONNXGraphLoader,
        ParamCounts,
    )
    from .hardware import HardwareEstimates, HardwareProfile
    from .patterns import Block, PatternAnalyzer
    from .risks import RiskAnalyzer, RiskSignal


@dataclass
class ModelMetadata:
    """Basic model metadata extracted from ONNX proto."""

    path: str
    ir_version: int
    producer_name: str
    producer_version: str
    domain: str
    model_version: int
    doc_string: str
    opsets: dict[str, int]  # domain -> version


@dataclass
class GraphSummary:
    """Summary statistics about the ONNX graph."""

    num_nodes: int
    num_inputs: int
    num_outputs: int
    num_initializers: int
    input_shapes: dict[str, list[int | str]]  # name -> shape (may have symbolic dims)
    output_shapes: dict[str, list[int | str]]
    op_type_counts: dict[str, int]  # op_type -> count


@dataclass
class InspectionReport:
    """
    Complete inspection report for an ONNX model.

    This is the primary output of ModelInspector.inspect() and contains
    all analysis results in a structured format suitable for JSON serialization
    or Markdown rendering.
    """

    # Metadata
    metadata: ModelMetadata
    generated_at: str = field(
        default_factory=lambda: datetime.utcnow().isoformat() + "Z"
    )
    autodoc_version: str = "0.1.0"

    # Graph structure
    graph_summary: GraphSummary | None = None

    # Metrics
    param_counts: ParamCounts | None = None
    flop_counts: FlopCounts | None = None
    memory_estimates: MemoryEstimates | None = None

    # Patterns
    detected_blocks: list[Block] = field(default_factory=list)
    architecture_type: str = (
        "unknown"  # "transformer", "cnn", "mlp", "hybrid", "unknown"
    )

    # Risks
    risk_signals: list[RiskSignal] = field(default_factory=list)

    # Hardware estimates (optional, set by CLI if --hardware specified)
    hardware_profile: HardwareProfile | None = None
    hardware_estimates: HardwareEstimates | None = None

    def to_dict(self) -> dict[str, Any]:
        """Convert report to a JSON-serializable dictionary."""
        import numpy as np

        # Track visited objects to prevent circular references
        visited: set = set()

        def _serialize(obj: Any, depth: int = 0) -> Any:
            # Prevent infinite recursion
            if depth > 50:
                return str(obj)

            # Check for circular references using object id
            obj_id = id(obj)
            if obj_id in visited:
                return "<circular reference>"
            if not isinstance(obj, (str, int, float, bool, type(None))):
                visited.add(obj_id)

            if obj is None:
                return None
            if isinstance(obj, (str, int, float, bool)):
                return obj
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            if isinstance(obj, (np.integer, np.floating)):
                return obj.item()
            # Handle dataclasses (but not by calling to_dict which would recurse)
            if hasattr(obj, "__dataclass_fields__"):
                return {
                    k: _serialize(getattr(obj, k), depth + 1)
                    for k in obj.__dataclass_fields__
                }
            if isinstance(obj, list):
                return [_serialize(item, depth + 1) for item in obj]
            if isinstance(obj, dict):
                return {str(k): _serialize(v, depth + 1) for k, v in obj.items()}
            # Fallback: convert to string
            return str(obj)

        return _serialize(self)

    def to_json(self, indent: int = 2) -> str:
        """Serialize report to JSON string."""
        return json.dumps(self.to_dict(), indent=indent)

    def to_markdown(self) -> str:
        """Generate a Markdown model card from this report."""
        lines = []

        # Header
        model_name = pathlib.Path(self.metadata.path).stem
        lines.append(f"# Model Card: {model_name}")
        lines.append("")
        lines.append(
            f"*Generated by ONNX Autodoc v{self.autodoc_version} on {self.generated_at}*"
        )
        lines.append("")

        # Metadata section
        lines.append("## Metadata")
        lines.append("")
        lines.append("| Property | Value |")
        lines.append("|----------|-------|")
        lines.append(f"| IR Version | {self.metadata.ir_version} |")
        lines.append(
            f"| Producer | {self.metadata.producer_name} {self.metadata.producer_version} |"
        )
        if self.metadata.opsets:
            opset_str = ", ".join(f"{d}:{v}" for d, v in self.metadata.opsets.items())
            lines.append(f"| Opsets | {opset_str} |")
        lines.append("")

        # Graph summary
        if self.graph_summary:
            lines.append("## Graph Summary")
            lines.append("")
            lines.append(f"- **Nodes**: {self.graph_summary.num_nodes}")
            lines.append(f"- **Inputs**: {self.graph_summary.num_inputs}")
            lines.append(f"- **Outputs**: {self.graph_summary.num_outputs}")
            lines.append(f"- **Initializers**: {self.graph_summary.num_initializers}")
            lines.append("")

            # Input/output shapes
            if self.graph_summary.input_shapes:
                lines.append("### Inputs")
                lines.append("")
                for name, shape in self.graph_summary.input_shapes.items():
                    lines.append(f"- `{name}`: {shape}")
                lines.append("")

            if self.graph_summary.output_shapes:
                lines.append("### Outputs")
                lines.append("")
                for name, shape in self.graph_summary.output_shapes.items():
                    lines.append(f"- `{name}`: {shape}")
                lines.append("")

            # Top operators
            if self.graph_summary.op_type_counts:
                lines.append("### Operator Distribution")
                lines.append("")
                lines.append("| Operator | Count |")
                lines.append("|----------|-------|")
                sorted_ops = sorted(
                    self.graph_summary.op_type_counts.items(), key=lambda x: -x[1]
                )
                for op, count in sorted_ops[:15]:  # Top 15
                    lines.append(f"| {op} | {count} |")
                if len(sorted_ops) > 15:
                    lines.append(f"| ... | ({len(sorted_ops) - 15} more) |")
                lines.append("")

        # Metrics
        if self.param_counts or self.flop_counts or self.memory_estimates:
            lines.append("## Complexity Metrics")
            lines.append("")

            if self.param_counts:
                lines.append(
                    f"- **Total Parameters**: {self._format_number(self.param_counts.total)}"
                )
                lines.append(
                    f"  - Trainable: {self._format_number(self.param_counts.trainable)}"
                )
                lines.append(
                    f"  - Non-trainable: {self._format_number(self.param_counts.non_trainable)}"
                )
                lines.append("")

            if self.flop_counts:
                lines.append(
                    f"- **Estimated FLOPs**: {self._format_number(self.flop_counts.total)}"
                )
                lines.append("")

            if self.memory_estimates:
                lines.append(
                    f"- **Model Size**: {self._format_bytes(self.memory_estimates.model_size_bytes)}"
                )
                lines.append(
                    f"- **Peak Activation Memory** (batch=1): "
                    f"{self._format_bytes(self.memory_estimates.peak_activation_bytes)}"
                )
                lines.append("")

        # Architecture
        if self.architecture_type != "unknown" or self.detected_blocks:
            lines.append("## Architecture")
            lines.append("")
            lines.append(f"**Detected Type**: {self.architecture_type}")
            lines.append("")

            if self.detected_blocks:
                lines.append("### Detected Blocks")
                lines.append("")
                # Group by block type
                block_types: dict[str, int] = {}
                for block in self.detected_blocks:
                    block_types[block.block_type] = (
                        block_types.get(block.block_type, 0) + 1
                    )
                for bt, count in sorted(block_types.items(), key=lambda x: -x[1]):
                    lines.append(f"- {bt}: {count}")
                lines.append("")

        # Hardware estimates
        if self.hardware_estimates and self.hardware_profile:
            hw = self.hardware_estimates
            lines.append("## Hardware Estimates")
            lines.append("")
            lines.append(f"**Target Device**: {self.hardware_profile.name}")
            lines.append(
                f"**Precision**: {hw.precision} | **Batch Size**: {hw.batch_size}"
            )
            lines.append("")
            lines.append("| Metric | Value |")
            lines.append("|--------|-------|")
            lines.append(
                f"| VRAM Required | {self._format_bytes(hw.vram_required_bytes)} |"
            )
            lines.append(f"| Fits in VRAM | {'Yes' if hw.fits_in_vram else 'No'} |")
            if hw.fits_in_vram:
                lines.append(
                    f"| Theoretical Latency | {hw.theoretical_latency_ms:.2f} ms |"
                )
                lines.append(f"| Bottleneck | {hw.bottleneck} |")
                lines.append(
                    f"| Compute Utilization | {hw.compute_utilization_estimate:.0%} |"
                )
            lines.append("")

            # Add device specs
            lines.append("### Device Specifications")
            lines.append("")
            lines.append(
                f"- **VRAM**: {self._format_bytes(self.hardware_profile.vram_bytes)}"
            )
            lines.append(
                f"- **FP32 Peak**: {self.hardware_profile.peak_fp32_tflops:.1f} TFLOPS"
            )
            lines.append(
                f"- **FP16 Peak**: {self.hardware_profile.peak_fp16_tflops:.1f} TFLOPS"
            )
            if self.hardware_profile.tdp_watts:
                lines.append(f"- **TDP**: {self.hardware_profile.tdp_watts}W")
            lines.append("")

        # Risks
        if self.risk_signals:
            lines.append("## Risk Signals")
            lines.append("")
            for risk in self.risk_signals:
                severity_icon = {"info": "INFO", "warning": "WARN", "high": "HIGH"}
                icon = severity_icon.get(risk.severity, "")
                lines.append(f"### [{icon}] {risk.id}")
                lines.append("")
                lines.append(risk.description)
                lines.append("")
                if risk.recommendation:
                    lines.append(f"**Recommendation**: {risk.recommendation}")
                    lines.append("")

        return "\n".join(lines)

    @staticmethod
    def _format_number(n: int | float) -> str:
        """Format large numbers with K/M/B suffixes."""
        if n >= 1e9:
            return f"{n / 1e9:.2f}B"
        if n >= 1e6:
            return f"{n / 1e6:.2f}M"
        if n >= 1e3:
            return f"{n / 1e3:.2f}K"
        return str(int(n))

    @staticmethod
    def _format_bytes(b: int) -> str:
        """Format bytes with KB/MB/GB suffixes."""
        if b >= 1e9:
            return f"{b / 1e9:.2f} GB"
        if b >= 1e6:
            return f"{b / 1e6:.2f} MB"
        if b >= 1e3:
            return f"{b / 1e3:.2f} KB"
        return f"{b} bytes"


class ModelInspector:
    """
    Main orchestrator for ONNX model analysis.

    Coordinates the loader, metrics engine, pattern analyzer, and risk analyzer
    to produce a comprehensive InspectionReport.

    Example:
        inspector = ModelInspector()
        report = inspector.inspect("model.onnx")
        report.to_json()
    """

    def __init__(
        self,
        loader: ONNXGraphLoader | None = None,
        metrics: MetricsEngine | None = None,
        patterns: PatternAnalyzer | None = None,
        risks: RiskAnalyzer | None = None,
        logger: logging.Logger | None = None,
    ):
        """
        Initialize ModelInspector with optional component overrides.

        Args:
            loader: Custom graph loader. If None, uses default ONNXGraphLoader.
            metrics: Custom metrics engine. If None, uses default MetricsEngine.
            patterns: Custom pattern analyzer. If None, uses default PatternAnalyzer.
            risks: Custom risk analyzer. If None, uses default RiskAnalyzer.
            logger: Logger for diagnostic output.
        """
        # Defer imports to avoid circular dependencies
        from .analyzer import MetricsEngine, ONNXGraphLoader
        from .patterns import PatternAnalyzer
        from .risks import RiskAnalyzer

        self.loader = loader or ONNXGraphLoader()
        self.metrics = metrics or MetricsEngine()
        self.patterns = patterns or PatternAnalyzer()
        self.risks = risks or RiskAnalyzer()
        self.logger = logger or logging.getLogger("autodoc")

    def inspect(self, model_path: str | pathlib.Path) -> InspectionReport:
        """
        Run full analysis pipeline on an ONNX model.

        Args:
            model_path: Path to the ONNX model file.

        Returns:
            InspectionReport with all analysis results.
        """
        model_path = pathlib.Path(model_path)
        self.logger.info(f"Inspecting model: {model_path}")

        # Load model
        model, graph_info = self.loader.load(model_path)

        # Extract metadata
        metadata = self._extract_metadata(model, model_path)

        # Build graph summary
        graph_summary = self._build_graph_summary(graph_info)

        # Compute metrics
        self.logger.debug("Computing metrics...")
        param_counts = self.metrics.count_parameters(graph_info)
        flop_counts = self.metrics.estimate_flops(graph_info)
        memory_estimates = self.metrics.estimate_memory(graph_info)

        # Detect patterns
        self.logger.debug("Detecting patterns...")
        detected_blocks = self.patterns.group_into_blocks(graph_info)
        architecture_type = self.patterns.classify_architecture(
            graph_info, detected_blocks
        )

        # Analyze risks
        self.logger.debug("Analyzing risks...")
        risk_signals = self.risks.analyze(graph_info, detected_blocks)

        report = InspectionReport(
            metadata=metadata,
            graph_summary=graph_summary,
            param_counts=param_counts,
            flop_counts=flop_counts,
            memory_estimates=memory_estimates,
            detected_blocks=detected_blocks,
            architecture_type=architecture_type,
            risk_signals=risk_signals,
        )

        self.logger.info(
            f"Inspection complete. Found {len(detected_blocks)} blocks, {len(risk_signals)} risks."
        )
        return report

    def _extract_metadata(self, model, model_path: pathlib.Path) -> ModelMetadata:
        """Extract metadata from ONNX ModelProto."""
        from .analyzer import get_opsets_imported

        opsets = get_opsets_imported(model)

        return ModelMetadata(
            path=str(model_path),
            ir_version=model.ir_version,
            producer_name=model.producer_name or "unknown",
            producer_version=model.producer_version or "",
            domain=model.domain or "",
            model_version=model.model_version,
            doc_string=model.doc_string or "",
            opsets=opsets,
        )

    def _build_graph_summary(self, graph_info) -> GraphSummary:
        """Build summary statistics from GraphInfo."""
        return GraphSummary(
            num_nodes=graph_info.num_nodes,
            num_inputs=len(graph_info.inputs),
            num_outputs=len(graph_info.outputs),
            num_initializers=len(graph_info.initializers),
            input_shapes=graph_info.input_shapes,
            output_shapes=graph_info.output_shapes,
            op_type_counts=graph_info.op_type_counts,
        )
